{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq__bChjD04e"
      },
      "source": [
        "# Python Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⏱⏱⏱**Due: 10/15/2023 11:59 PM** ⏱⏱⏱\n",
        "\n",
        "Please submit your notebook files and upload them to your Git repository. Don't forget to include a link to your Git repository when submitting this file on Brightspace.\n",
        "\n",
        "Collaboration is permitted and encouraged; however, it's essential to independently produce and submit your own work. If you collaborate with others, please ensure that you provide their names in the designated section.\n",
        "\n",
        "Collaborators:_____"
      ],
      "metadata": {
        "id": "y7j2V0UDMYLG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUS30Ew9D04n"
      },
      "source": [
        "(150 points total)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have provided some guidance in comments to help you through the steps, but feel free to approach this in a different way if you prefer. **Feel free to disregard my comments if you have an alternative approach in mind.**"
      ],
      "metadata": {
        "id": "SQ8W8KvamwFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Good presentation of your code and outputs; submitting your files to Github (10 pts)"
      ],
      "metadata": {
        "id": "KR0Fl4yAQYad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure thorough and clear comments within your code to explain its functionality.\n",
        "\n",
        "Enhance your plots by adding titles, legends, and axis labels where appropriate to provide clarity.\n",
        "\n",
        "If necessary, employ LaTex notation to present mathematical explanations within the notebook.\n",
        "\n",
        "Divide your code into multiple blocks or cells in Jupyter Notebook and provide descriptive explanations for each block to improve readability.\n",
        "\n",
        "As part of your submission, include the notebook files and upload them to your Git repository. Additionally, remember to provide a link to your Git repository when submitting the files on Brightspace.\n",
        "\n",
        "Please adhere to the constraint of using only the `numpy`, `scipy`, and `matplotlib` libraries for this assignment, as it is feasible to complete the task without introducing additional libraries or packages.\n",
        "\n"
      ],
      "metadata": {
        "id": "9WPZWhYQkptT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Implementing Gradient Descent Algorithm (60 pts)"
      ],
      "metadata": {
        "id": "E1RrC_zGPPkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a function $f(x) = \\sqrt{x^2+5}$, $x\\in \\mathbf{R}$.\n",
        "\n",
        "Fact: This function is L-smooth.\n",
        "0. Find the gradient of this function and the minimum value of this function analytically.\n",
        "\n",
        "\n",
        "1. Plot this function over the interval $[-5, 5]$.\n",
        "2. Perform the Gradient Descent algorithm to find the minimum value of $f$ for $50$ iterations ($T$) with a step size of $1$ ($\\alpha$). Use the last digit of your SB ID divided by 5 and then plus 1 as the initial guess (for example, if your ID ends with 9, your initial guess $x_0$ will be $9\\div5 + 1= 2.8$).\n",
        "3. Record the values of $x_k$ at the $k$-th iteration during GD and report $x_T$.\n",
        "4. Plot the value of $f(x_k)$ v.s. the iteration number $k$.\n",
        "5. For each of the step sizes 5, 3, 1, and 0.5, perform gradient descent and record the values of $x_k$ in each step $k$. Plot $f(x_{k-1}) - f(x_{k})$ v.s. $k$ for each step size. Your graphs should all be included in a single plot. Examine if $f(x_{k-1}) - f(x_{k})$ (which means that $f(x_k)$ is always decreasing) is alway positive for all $k$."
      ],
      "metadata": {
        "id": "k4UbpYwuWxcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some sample output graphs. Yours do not have to look exactly like mine, it is just for your reference.\n",
        "![o1](https://raw.githubusercontent.com/wenhangao21/AMS595-Teaching/main/o1.png)\n",
        "![o2](https://raw.githubusercontent.com/wenhangao21/AMS595-Teaching/main/o2.png)\n",
        "![o3](https://raw.githubusercontent.com/wenhangao21/AMS595-Teaching/main/o3.png)\n",
        "\n",
        "Please note that the graphs generated as output may not precisely match the ones I'm providing here. The disparities could be significant, as I'm presenting a general overview of the expected graph. I've adjusted certain parameters/plot information in the graph generation process to prevent disclosing the \"answer/solution\".&nbsp;\n"
      ],
      "metadata": {
        "id": "yyFNzkLNqaLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the function f(x).\n",
        "def f(x):\n",
        "    return np.sqrt(x**2 + 5)\n",
        "# After defining the function F(X), I found the gradient of the function dF(x)/dx\n",
        "def df(x):\n",
        "    return x / np.sqrt(x**2 + 5)\n",
        "# I found the minimum of F(x) which at x=0 because x^2 will make F(x) positive regardless of the value of x. Therefore, F(x) will be minimum at x=0\n",
        "# I then made the minimum value of f(x)=f(0) to equivalent to a. f(0)=a for simplicity of the code\n",
        "a = f(0)\n",
        "\n",
        "# Plot the function f(x), np.linspace might be helpful.\n",
        "# I made x to range from -5 and 5 and note that x^2 in f(x) equate f(-x) =f(x) and f(0) is the minimum. From this, I could tell that the graph would be parabolic. I used a step of 100.\n",
        "x_values = np.linspace(-5, 5, 100)\n",
        "y_values = f(x_values)\n",
        "\n",
        "plt.figure(figsize=(8, 6)) # I used a reasonable graph size of 8by6 since the value of f(x) is 5.5\n",
        "plt.plot(x_values, y_values, label='f(x)')\n",
        "plt.xlabel('x')  # I label the x-axis as x\n",
        "plt.ylabel('f(x)') # I label the y-axis as f(x)\n",
        "plt.title('Gradient Decent to find the Minimum') # I titled the graph as given in the sample shown above\n",
        "plt.axhline(a, color='red', linestyle='--', label='Minimum Value') # I could not get how to dot the minimum so i used breaking lines to represent the minimum\n",
        "plt.legend()  # I showed the legend of the curve representing f(x) and the line representing the minimum value in a printable format.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1FB20kJ3mFOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the derivative of the function f(x), for gradient descent\n",
        "# I defined it earlier in the first section, I found the gradient of the function df(x)/dx\n",
        "def df(x):\n",
        "    return x / np.sqrt(x**2 + 5)\n",
        "\n",
        "# write a function to run the Gradient Descent Algorithm, take input arguments x_0, step_size, and num_iterations; return a list/array of x_k values.\n",
        "# I define the function as gradient_descent\n",
        "def gradient_descent(initial_x, alpha, num_iterations):\n",
        "    t = [initial_x]  # I used t to represent the intial values of x\n",
        "    for _ in range(num_iterations):\n",
        "        x = t[-1]\n",
        "        x_new = x - alpha * df(x)\n",
        "        t.append(x_new)\n",
        "    return t\n",
        "\n",
        "\n",
        "# set up/assign initial values\n",
        "# As part of my intial values is my intial guess which is gotten from my SBU ID last digit:115360301\n",
        "# the last digit from my SBU ID is 1 and using 1/5+1 my initial guess =1.2\n",
        "alpha = 1\n",
        "T = 50  # T is the number of Itegrations\n",
        "initial_guess = 1.2\n",
        "z = gradient_descent(initial_guess, alpha, T) # I made z to be equal to my defined function gradient_descent\n",
        "x_T = z[-1]\n",
        "\n",
        "\n",
        "\n",
        "# Run gradient descent by calling the function\n",
        "w = f(np.array(z))\n",
        "\n",
        "\n",
        "# report x_T by printing out the value\n",
        "\n",
        "print(f'x_T: {x_T}')\n",
        "\n",
        "# Plot the f($x_k$) values vs. iteration number\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(T+1), w, label='f($x_k$)')  # the $ is to write the subscript\n",
        "plt.xlabel('Iteration (k)')\n",
        "plt.ylabel('f($x_k$)')\n",
        "plt.title('GD: f($x_k$) vs. Iteration (k)')\n",
        "plt.legend()  # I showed the legend of the curve representing f(x_k)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2umIP9i5mT1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list containing step sizes\n",
        "# My list contain step size of 5,3,1, and 0.5\n",
        "s = [5, 3, 1, 0.5] # I used s to represent the step sizes list\n",
        "\n",
        "\n",
        "# initialize a list to store the results from different step sizes\n",
        "plt.figure(figsize=(8, 6))\n",
        "# I initialized the list created using for loop\n",
        "for alpha in s: # s is the step sizes list defined previously.\n",
        "    z = gradient_descent(initial_guess, alpha, T) # I called z that I define earlier.\n",
        "    w= f(np.array(z))\n",
        "    c = w[:-1] - w[1:]\n",
        "    plt.plot(range(1, T+1), c, label=f'alpha={alpha}')\n",
        "\n",
        "\n",
        "# loop through the step sizes and perform GD and record results\n",
        "plt.xlabel('Iteration (k)')\n",
        "plt.ylabel('f($x_{k-1}$) - f($x_k$)')\n",
        "plt.title('f($x_{k-1}$) - f($x_k$) vs. Iteration (k) for Different Step Sizes')\n",
        "plt.legend()\n",
        "# plt.ylim(-1, 2.5)  # Set y-axis limits\n",
        "# plt.yticks(np.arange(-1, 2.6, step=0.5))  # I set y-axis ticks with step size of 0.5\n",
        "# I tried making it similiar to the sample but my result didn't make sense.\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# plot multiple curves in a single graph\n"
      ],
      "metadata": {
        "id": "vjLjdTvYnUpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Linear Regression with Numpy and Graphing with Matplotlib (30 pts)"
      ],
      "metadata": {
        "id": "b_bgT3b2GYTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In class, we implemented a linear regression model with one-dimensional features ( $x$-values). However, below, you will find the code for generating synthetic data where the features ( $x$-values) are now two-dimensional.\n",
        "\n",
        "**Change the random seed to be the last two digits of your student ID. For example, if your ID is 123456987, change the random seed to be 87.**\n",
        "\n",
        "The next step involves performing linear regression on this newly generated data. We will employ the normal equation, a topic covered in class, to determine the coefficients and intercept (weights and bias).\n",
        "\n",
        "**Report the parameter values and plot the generated data and the regression plane (in 1D, we have a line, but in 2D, we have a plane).** `numpy.linspace`, `numpy.meshgrid`, and [Surface Plot](https://matplotlib.org/stable/gallery/mplot3d/surface3d.html) methods might be helpful in plotting the plane. You don't have to use them, it is just my suggestions.\n",
        "\n",
        "Here are some sample output graphs. Yours do not have to look exactly like mine, it is just for your reference.\n",
        "![o1](https://raw.githubusercontent.com/wenhangao21/AMS595-Teaching/main/o4.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "3dMvUP6qJQsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(1)   # change the seed to be the last two digits of your SB ID. My SBU ID is 11360301 and last two digit is 01 which implies 1\n",
        "num_samples=100\n",
        "X = 2 * np.random.rand(100, 2)  # Generate 100 random 2D data points\n",
        "y = 4 + 4 * X[:, 0] + 0.5 * X[:, 1] + np.random.randn(100)  # Generate y values with noise\n",
        "\n",
        "# Add a column of ones to X for the bias terms (intercept) in the normal equation\n",
        "X_b = np.c_[np.ones((num_samples, 1)), X]  # Add bias term\n",
        "\n",
        "\n",
        "# Find theta using the normal equation\n",
        "theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "# I extracted coefficients (weights) and intercept (bias)\n",
        "bias = theta[0]\n",
        "weight_1 = theta[1]\n",
        "weight_2 = theta[2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the intercept and coefficients of the regression plane\n",
        "print(f'Intercept (Bias): {bias}')\n",
        "print(f'Weight for Feature 1: {weight_1}')\n",
        "print(f'Weight for Feature 2: {weight_2}')\n",
        "\n",
        "\n",
        "\n",
        "# Plot the generated data and the regression plane\n",
        "x1_range = np.linspace(0.0, 2.0, 12) # I could not get how to step make the similiar to the sample of step 0.5\n",
        "x2_range = np.linspace(0.0, 2.0, 12)\n",
        "\n",
        "# I calculated the predictions for the regression plane\n",
        "x1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)\n",
        "y_pred = bias + weight_1 * x1_mesh + weight_2 * x2_mesh\n",
        "\n",
        "# Plot the generated data\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "ax.scatter(X[:, 0], X[:, 1], y, c='b', marker='o', label='Original Data')  # Scatter plot of data points\n",
        "\n",
        "# Plot the regression plane\n",
        "taiwo = ax.plot_surface(x1_mesh, x2_mesh, y_pred, alpha=0.5, rstride=100, cstride=100,)\n",
        "\n",
        "# I set labels as x_1 and x_2\n",
        "ax.set_xlabel('$x_1$')\n",
        "ax.set_ylabel('$x_2$')\n",
        "ax.set_zlabel('Target Variable')\n",
        "fig.colorbar(taiwo) # I added colour bar so that the regression plane could come in different colour\n",
        "plt.title('Linear Regression Plane')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QyUVB8pkJQNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Logistic Regression with Numpy and Graphing with Matplotlib (20 pts)"
      ],
      "metadata": {
        "id": "2UaGJmh1PZ0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In class, we implemented a logistic regression model to perform binary classification. Here, I provided the exact same code that we discussed in class, but the values for learning_rate and num_epochs are modified. I also removed all the comments. You task is to\n",
        "1. Tune the Learning Rate and Number of Epochs: Your first task is to fine-tune the values for the learning_rate and num_epochs parameters. Your goal is to identify suitable values that will enable us to converge to a set of parameter values $\\theta$ closely approximating the optimal parameter values $\\theta^*$.\n",
        "2. Code Explanation: To enhance code comprehension, please augment the code with meaningful comments. These comments should elucidate the purpose and functionality of each code segment, making it easier for readers to understand the logistic regression implementation.\n",
        "\n",
        "By accomplishing these tasks, we aim to achieve a better understanding of the logistic regression model's behavior and its parameter optimization process."
      ],
      "metadata": {
        "id": "hPiFkVozoO9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Setting  a random seed of 585 for reproducibility\n",
        "np.random.seed(585)\n",
        "# Generating random synthetic data\n",
        "X = np.random.rand(2, 100)\n",
        "w_true = np.array([1.5, -2.5])\n",
        "b_true = 1.0  # True bias\n",
        "\n",
        "# Calculating probabilities and generate labels\n",
        "probabilities = sigmoid(np.dot(w_true.T, X) + b_true)\n",
        "Y = (probabilities > 0.5).astype(int)\n",
        "\n",
        "# Adding some noise to the data\n",
        "X = X + 0.3 * np.random.rand(2, 100) - 0.1 * np.random.rand(2, 100)\n",
        "\n",
        "\n",
        "# Spliting data into training and test sets\n",
        "X_train, X_test = X[:,:80], X[:,80:]\n",
        "Y_train, Y_test = Y[:80], Y[80:]\n",
        "\n",
        "# Initializing weights and bias\n",
        "w = np.zeros(X.shape[0])\n",
        "b = 0.0\n",
        "\n",
        "\n",
        "# Setting learning rate and number of epochs\n",
        "learning_rate = 5.80 # I set the learning rate to 5.80 and num_epochs to 585. I achieve a test set accuracy of 100%\n",
        "num_epochs = 585\n",
        "\n",
        "# Training the logistic regression model for weight of bias\n",
        "for epoch in range(num_epochs):\n",
        "    A_train = sigmoid(np.dot(w.T, X_train) + b)\n",
        "\n",
        "    dJdw = np.dot(X_train, (A_train - Y_train).T) / len(Y_train)\n",
        "    dJdb = np.mean(A_train - Y_train)\n",
        "\n",
        "    w -= learning_rate * dJdw\n",
        "    b -= learning_rate * dJdb\n",
        "\n",
        "# Making predictions on the training set\n",
        "A_train = sigmoid(np.dot(w.T, X_train) + b)\n",
        "predictions_train = (A_train > 0.5).astype(int)\n",
        "\n",
        "# Making predictions on the test set\n",
        "A_test = sigmoid(np.dot(w.T, X_test) + b)\n",
        "predictions_test = (A_test > 0.5).astype(int)\n",
        "\n",
        "# Calculating accuracy\n",
        "train_accuracy = np.mean(predictions_train == Y_train)\n",
        "\n",
        "test_accuracy = np.mean(predictions_test == Y_test)\n",
        "# Printing the result\n",
        "print(f\"Training Set Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "gsISUaPppsSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[0, :80], X[1,:80], c=Y[:80], cmap=plt.cm.Paired) # Scattering plot the first 80 data points from X\n",
        "\n",
        "# Setting the x and y axis limits\n",
        "plt.xlim(-0.2, 1.2)\n",
        "plt.ylim(-0.2, 1.2)\n",
        "ax = plt.gca()   # Getting the current axis\n",
        "\n",
        "#  Getting the current x and y axis limits\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "# Creating a meshgrid for plotting the decision boundary\n",
        "xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 50), np.linspace(ylim[0], ylim[1], 50))\n",
        "\n",
        "# Calculating the values of Z using the logistic regression model\n",
        "Z = np.dot(w.T, np.c_[xx.ravel(), yy.ravel()].T) + b\n",
        "Z = sigmoid(Z)\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plotting the decision boundary\n",
        "plt.contour(xx, yy, Z, colors='k', levels=[0.5], alpha=0.5, linestyles=['--'])\n",
        "\n",
        "# Labeling the x and y axes\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Logistic Regression Decision Boundary') # Giving the plot a title\n",
        "plt.show() # Displaying the plot"
      ],
      "metadata": {
        "id": "gaSc4w_Bp6gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[0, 80:], X[1, 80:], c=Y[80:], cmap=plt.cm.Paired) # Scattering plot the first 80 data points from X\n",
        "plt.xlim(-0.2, 1.2)\n",
        "plt.ylim(-0.2, 1.2)\n",
        "\n",
        "ax = plt.gca()\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 50), np.linspace(ylim[0], ylim[1], 50))\n",
        "Z = np.dot(w.T, np.c_[xx.ravel(), yy.ravel()].T) + b\n",
        "Z = sigmoid(Z)\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contour(xx, yy, Z, colors='k', levels=[0.5], alpha=0.5, linestyles=['--'])\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Logistic Regression Decision Boundary')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jKSMwrjMqA7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Image Binary Classification (30 pts)\n",
        "\n"
      ],
      "metadata": {
        "id": "tw90j2QVP07p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Question 5 of the Python project, please complete it using two distinct Jupyter Notebook scripts. This entails using one notebook for the original dataset and another for the modified dataset. Consequently, you will be submitting a total of three .ipynb files as part of your Python project, ensuring clear separation and organization of your work.\n",
        "\n",
        "Your tasks:\n",
        "1. Your first task is to re-implement the classification model that was covered in our class. Please start from scratch and write the code independently. You can refer to the original code provided on Brightspace if you encounter any difficulties, but try to write the code on your own to reinforce your understanding.\n",
        "\n",
        "2. After implementing the classification model, **report the indices of all the images in the test set for which the model's predictions are incorrect.** To maintain consistency with Python’s convention, please begin your indexing with 0. Additionally, **display the images of 4 of these failed cases for visual examination (you can display more if you like)**. This analysis might help us identify instances where the model is struggling in some applications.\n",
        "\n",
        "3. Now you will modify the code to treat the dataset differently. The first 160 images plus the last digit of your Student ID will constitute the new training set, while the remaining images in the original training set will be your new test set. There are 209 images in the original training set. For example, if your ID ends with 0, the first 160 images will form your training set, and the remaining 49 images will be part of your test set. The test dataset is discarded and no longer used. Re-train the model using this modified dataset and **report the training and test accuracies**. Additionally, **provide the indices of all the images in the test set for which the model's predictions are incorrect. Display 4 of these misclassified images for further examination.**\n",
        "\n",
        "By completing these tasks, you'll gain valuable insights into the classification model's performance and its behavior under different training and testing conditions."
      ],
      "metadata": {
        "id": "FjdUaeQ-rbO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " Download datasets: [train](https://drive.google.com/file/d/1I1_zbX9aqvl7FaRW1qR36R4PCL7awBlH/view?usp=drive_link), [test](https://drive.google.com/file/d/1nDk_E5crLPsmLKwq8iykS8s26Xerf_X0/view?usp=drive_link)"
      ],
      "metadata": {
        "id": "ClgZIN_-P8Hv"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}